{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #                  Wrangling Report\n",
    "   ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Purpose of this project is to wrangle and analyze data from the [We Rate Dogs](https://twitter.com/dog_rates) twitter account. The account is know for posting pictures of dogs with funny comments and rating the dogs out of ten, with numbers greater than 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data for this project was gathered from three different sources\n",
    "* The WeRateDogs Twitter archive which was provided to Udacity and stored in a file called twitter_archive_enhanced.csv. This was downloaded manually and read into a dataframe using the ```Pandas.read_csv``` funtion\n",
    "* An image predictions file (image_predictions.tsv) which shows what breed of dog is present in each tweet predicted by a neural network. This was accessed using the ```Requests``` library and stored into a separate dataframe\n",
    "* tweet_json.txt which was queried from Twitter's API using tweepy containing each tweets retweet count and favorite count. The .txt file was read line by line into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was assessed using both visual and programatic assessment\n",
    "* Visual assessment was carried out by printing out the dataframes in the notebook and also opening them as excel files to see the data that had been hidden away\n",
    "* Programatic assessment was carried out using ```df.info()```, ```df.describe()```, ```df['series'].value_counts()``` and ```df['series'].isnull()``` functions on each table and specific columns in the tables\n",
    "\n",
    "The issues found were separated into quality issues and tidiness issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each issue documented in the assessing data section was dealt with separately, using the define, code and test system to work through them. \n",
    "* The rows containing retweets and replies were removed and the respective columns were dropped from the Twitter archive dataframe. \n",
    "* The source column was also dropped. \n",
    "* The datatype in the Timestamp column was changed from object to datetime. \n",
    "* The tweet id columns were changed to categorical datatypes\n",
    "* All three tables were merged into one master table\n",
    "* The correct numerator and denominator ratings were extracted from the text column\n",
    "* The short url's were extracted from the text columns and the extended url column was dropped\n",
    "* The image number and predictions 2 and 3 columns were dropped\n",
    "* Doggo, Floofer, Puppo and Pupper columns were melted into one column called dog types\n",
    "* Columns were rearranged to create a better flow\n",
    "* Columns were renamed to be better understood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This project made clear of the fact that data rarely ever comes in one tidy and clean format. Extra steps will always have to be taken to gather the data from different sources and also to assess and clean the data in order to be able to create actionable insights and visualizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
